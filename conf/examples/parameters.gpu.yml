tokenize:
  model_name_or_path: "gpt2"
  max_length: 128
  local_files_only: false

extract_activations:
  tokenized_pkl_path: "data/02_intermediate/prompts_tokenized.pkl"
  model_name_or_path: "gpt2"
  output_root: "data/03_primary/activations"
  layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
  shard_size: 1
  batch_size: 1
  local_files_only: false
  use_gpu_for_forward: true
  torch_dtype: "float16"
  device_mode: "cuda"
  allow_cpu_fallback: false

metrics_generate:
  mode: "stub"
